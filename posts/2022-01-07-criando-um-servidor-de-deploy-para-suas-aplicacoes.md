---
title: Criando um servidor de deploy para suas aplicaÃ§Ãµes
description: Como criar um servidor simples e eficiente para rodar suas
  aplicaÃ§Ãµes em produÃ§Ã£o
date: 2022-01-13 03:59:55
image: assets/img/deploy.png
category: dev
background: "#637a91"
---
## IntroduÃ§Ã£o

Quando estamos comeÃ§ando a programar e fazendo nossas primeiras aplicaÃ§Ãµes para testes, chega uma hora que precisamos realmente colocar elas para rodar, e estÃ¡ tudo rodando perfeitamente no ambiente de desenvolvimento da nossa mÃ¡quina, mas entÃ£o vem a pergunta, como colocar isso para todo mundo usar? Muitas vezes nÃ£o sabemos como fazer para criar um ambiente minimamente viÃ¡vel para que outras pessoas possam ter acesso as nossas aplicaÃ§Ãµes, e eu mesmo, na primeira que vez que fui fazer isso, demorei umas duas semanas para realmente descobrir o jeito mais simples e viÃ¡vel de ser feito.

EntÃ£o nesse post, vou mostrar como configurar um servidor de maneira simples, porÃ©m eficiente, para estar rodando suas aplicaÃ§Ãµes.

## Os agentes do servidor

O primeiro passo, e o mais importante, Ã© entendermos o que vai estar acontecendo no nosso servidor, quais sÃ£o os agentes e o que cada um deles faz, por que com esse entendimento, fica muito mais fÃ¡cil de entender que nÃ£o Ã© a ferramenta â€œxâ€ ou â€œyâ€ que faz determinado papel, e sim, que vocÃª tem vÃ¡rias ferramentas para desempenhar cada papel.

Criaremos um ambiente com os seguintes agentes:

![Um fluxograma mostrando os agentes do servidor: ServiÃ§o da aplicaÃ§Ã£o, Gerenciado de serviÃ§os, Proxy reverso, Gerenciador de certificados](assets/img/deploy01.png "Os agentes do servidor")

* **ServiÃ§o da aplicaÃ§Ã£o**: O serviÃ§o que vai rodar dentro do seu servidor, por exemplo, quando vocÃª estÃ¡ executando sua aplicaÃ§Ã£o em desenvolvimento, ela tem um serviÃ§o que Ã© responsÃ¡vel por manter ela funcionando, da mesma forma aqui, sendo que podem ser vÃ¡rios serviÃ§os de diferentes aplicaÃ§Ãµes.
* **Gerenciado de serviÃ§os**: Ã‰ o responsÃ¡vel por manter todos os serviÃ§os funcionando, nele vocÃª consegue ver os logs de cada serviÃ§o, ele vai reiniciar o serviÃ§o sozinho caso ele caia, e nele vocÃª vai poder configurar todas as polÃ­ticas de como vocÃª deseja que estes serviÃ§os funcionem.
* **Proxy reverso**: Faz um papel de recepcionista do seu servidor, ele que vai encaminhar cada requisiÃ§Ã£o para o serviÃ§o certo, por exemplo, se eu acessar o servidor pelo endereÃ§o â€œserver01.com.brâ€, ele vai me encaminhar para o â€œserviÃ§o01â€, que eu configurei previamente.
* **Gerenciador de certificados**: ResponsÃ¡vel por criar e manter os certificados ssl das nossas aplicaÃ§Ãµes.

Agora vamos dar nomes aos bois, mas lembrando que existem vÃ¡rias alternativas para desempenhar cada um desses papeis, e cabe a vocÃª entender o que se encaixa melhor para cada situaÃ§Ã£o, mas as ferramentas que vamos utilizar aqui tambÃ©m sÃ£o excelentes, e sÃ£o Ã³timas opÃ§Ãµes para comeÃ§ar.

EntÃ£o, para o nosso exemplo, vamos utilizar o Node.js para construir o serviÃ§o da nossa aplicaÃ§Ã£o, o PM2 para gerenciar o serviÃ§o, o Nginx como proxy reverso, e o Certbot para lidar com os nossos certificados.

![Um fluxograma mostrando as aplicaÃ§Ãµes dos agentes do servidor: Node.js, PM2, Nginx, Certbot](assets/img/deploy02.png "Os agentes do servidor")

## Servidor da aplicaÃ§Ã£o

Como utilizaremos o Node.js nesse exemplo, o primeiro passo Ã© estar instalando ele no seu servidor, neste exemplo, vamos estar utilizando como servidor o Ubuntu Server 20.04. Se vocÃª quiser testar essa abordagem de um modo fÃ¡cil, vocÃª pode instalar um container do Ubuntu, seguindo este outro post: [Criando um servidor Ubuntu no Docker | Arthur Pedroti](https://dev.arthurpedroti.com.br/criando-um-servidor-ubuntu-no-docker/)

Para instalar o node, execute os seguintes comandos:

```jsx
cd ~
curl -sL https://deb.nodesource.com/setup_14.x -o nodesource_setup.sh
sudo apt install nodejs
```

Para verificar se o node foi instalado corretamente, digite:

```bash
node -v
```

```jsx
// Output
v14.4.0
```

Agora iremos instalar o npm(o gerenciador de pacotes do node), e para garantir que ele esteja funcionando corretamente, instalamos depois uma build de pacotes essenciais:

```bash
sudo apt install npm
sudo apt install build-essential
```

Agora vamos criar uma aplicaÃ§Ã£o de um Ãºnico arquivo, sÃ³ para simular uma aplicaÃ§Ã£o real:

```bash
cd ~
nano hello.js
```

```jsx
// hello.js
const http = require('http');

const hostname = '0.0.0.0';
const port = 3000;

const server = http.createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World!\n');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
```

Salve o arquivo e pronto, esse Ã© apenas uma aplicaÃ§Ã£o que ouve na porta 3000 em localhost e retorna â€œHello Worldâ€.

Pra verificar que estÃ¡ funcionando, apenas execute:

```bash
node hello.js
```

E vocÃª recebera a seguinte mensagem: `Server running at http://localhost:3000/`

Para sair da execuÃ§Ã£o da aplicaÃ§Ã£o, pressione `Ctrl+c`.

## Gerenciador de serviÃ§os

Agora iremos instalar o PM2 para gerenciar os serviÃ§os, como o que acabamos de executar com o node.

Para instalar utilizaremos o npm, execute o comando:

```bash
sudo npm install pm2@latest -g
```

E agora iremos executar o serviÃ§o do node que acabamos de criar pelo PM2:

```bash
pm2 start hello.js
```

VocÃª pode consultar os serviÃ§os que estÃ£o rodando pelo comand `pm2 list`

![Imagem da tabela que mostra os serviÃ§os no PM2](assets/img/deploy03.png "\"pm2 list\" output")

Como vocÃª pode ver, ele assumiu o nome do nosso arquivo como o nome de serviÃ§o, e agora ele jÃ¡ estÃ¡ gerenciando esse serviÃ§o, e mesmo que a aplicaÃ§Ã£o tenha algum crash, ele jÃ¡ vai automaticamente reiniciar para vocÃª.

Agora vamos executar um comando para que o PM2 seja executado ao inicializar o sistema, com uma lista de serviÃ§os previamente salva.

```bash
pm2 startup systemd
```

E comando abaixo salva a lista atual de serviÃ§os que estÃ£o rodando como a lista padrÃ£o para quando o servidor inicializar:

```bash
pm2 save
```

E para monitorar os serviÃ§os, vocÃª tambÃ©m pode usar o comando `pm2 monit`

## Proxy reverso

Agora vamos configurar o nosso recepcionista, que vai encaminhar as requisiÃ§Ãµes que chegam no nosso servidor direto para o serviÃ§o do hello.js, lembrando que o serviÃ§o do hello.js estÃ¡ rodando em localhost na porta 3000.

E para isso vamos instalar o Nginx:

```bash
apt install nginx
```

O Nginx funciona da seguinte forma, ele possui duas pastas principais, a â€œsites-availableâ€ e a â€œsites-enabledâ€. E elas funcionam da seguinte maneira, na pasta â€œsites-avaiableâ€, nÃ³s colocamos as configuraÃ§Ãµes de cada uma das nossas aplicaÃ§Ãµes, e se quisermos habilitar essa configuraÃ§Ã£o, criamos um link simbÃ³lico (vulgo atalho, mas esse Ã© o nome dado no linux), desse arquivo de configuraÃ§Ã£o para a pasta â€œsites-enabledâ€.

Na prÃ¡tica serÃ¡ assim, vamos acessar a pasta de â€œsites-availableâ€: 

```bash
cd /etc/nginx/sites-available/
```

Copiar a configuraÃ§Ã£o default:

```bash
cp default hello
```

E ajustar a configuraÃ§Ã£o nesse novo arquivo:

```bash
nano hello
```

Arquivo hello:

```bash
server {
        server_name hello.com.br;

server_name _;

location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
```

Se atentando que a linha 2, diz qual serÃ¡ o endereÃ§o de referÃªncia, e a linha 7, para onde o Nginx deve encaminhar o cliente quando ele solicitar esse endereÃ§o.

Ou seja, essa configuraÃ§Ã£o diz que quando vocÃª digitar â€œhello.com.brâ€, vocÃª vai direto para a nossa aplicaÃ§Ã£o do hello.js, que estÃ¡ rodando no â€œlocalhost:3000â€.

E para habilitar essa configuraÃ§Ã£o, vamos atÃ© a pasta de â€œsites-enabledâ€:

```bash
cd ..
cd sites-enabled/
```

E criar o nosso link simbÃ³lico:

```bash
ln -s /etc/nginx/sites-available/hello hello
```

Em seguida deletamos o link simbÃ³lico do arquivo default:

```bash
rm default
```

E para testar se a configuraÃ§Ã£o estÃ¡ funcionando corretamente, executamos:

```bash
nginx -t
```

```jsx
// Output
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

Agora iremos reiniciar o serviÃ§o do nginx:

```jsx
service nginx reload
service nginx restart
```

Por fim, vamos habilitar as portas 80 e 443 do nosso servidor para ele que possa estar ouvindo as requisiÃ§Ãµes por elas sem nenhum bloqueio:

```jsx
ufw allow 80
ufw allow 443
```

### Entendendo melhor

Lembrando que dessa forma nÃ³s estamos configurando para que ao digitar â€œhello.com.brâ€ vocÃª seja encaminhado a porta 3000 do localhost, pelo prÃ³prio nginx, mas para que isso funcione, o DNS do domÃ­nio â€œhello.com.brâ€ tem que estar sendo direcionado corretamente para o ip do seu servidor.

Por exemplo, se o ip do seu servidor Ã© â€œ192.168.2.200â€, entÃ£o ao acessar â€œ192.168.2.200:3000â€, vocÃª jÃ¡ vai estar acessando diretamente o hello.js, por que vocÃª estÃ¡ indicando a porta em que ele estÃ¡ sendo executado, enquanto para acessar pelo domÃ­nio â€œhello.com.brâ€, vocÃª deve primeiro configurar o DNS para esse domÃ­nio apontar para o ip â€œ192.168.2.200â€, e quando vocÃª acessar o domÃ­nio, que vai estar encaminhando para o ip correspondente, o Nginx vai entender aquela requisiÃ§Ã£o e associar a configuraÃ§Ã£o que vocÃª fez, e direcionar aquela requisiÃ§Ã£o para a porta 3000.

Ou seja, o papel do proxy reverso Ã© de permitir que vocÃª acesse o domÃ­nioâ€œhello.com.brâ€ sem ter que indicar uma porta nele, como â€œhello.com.br:3000â€, por que o proxy reverso que vai ter a configuraÃ§Ã£o prÃ©via para saber que porta ele deve direcionar cada requisiÃ§Ã£o de acordo com o endereÃ§o utilizado.

## Gerenciador de certificados

Por fim, vamos criar um certificado SSL para o nosso domÃ­nio, e para isso iremos utilizar o [Certbot](https://certbot.eff.org/). Para isso, vamos verificar se o snap estÃ¡ na sua versÃ£o mais recente:

```jsx
snap install core
snap refresh core
```

E depois vamos instalar o certbot:

```jsx
snap install --classic certbot
```

Preparando o comando do certbot:

```jsx
ln -s /snap/bin/certbot /usr/bin/certbot
```

Executando o certbot e gerando o certificado:

```jsx
sudo certbot --nginx
```

## Concluindo

Pronto, agora seu domÃ­nio jÃ¡ possui um certificado SSL, o Nginx jÃ¡ estÃ¡ encaminhando todas as requisiÃ§Ãµes para o serviÃ§o correto, e o PM2 nos garante que a sua aplicaÃ§Ã£o vai ficar ativa 24/7.

Espero que este post tenha de ajudado um pouco a pelo menos sair do 0, entender como funciona, e quais sÃ£o os papeis e elementos para colocar uma aplicaÃ§Ã£o em produÃ§Ã£o. Se vocÃª tem alguma dÃºvida ou sugestÃ£o, nÃ£o deixe de comentar aqui em baixo, atÃ© a prÃ³xima.ğŸ˜‰